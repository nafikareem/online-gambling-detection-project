{
  "best_global_step": 1338,
  "best_metric": 0.993640124797821,
  "best_model_checkpoint": "../../models/indoBERT\\checkpoint-1338",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 1338,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014947683109118086,
      "grad_norm": 4.967031955718994,
      "learning_rate": 4.9750871948181365e-05,
      "loss": 0.2984,
      "step": 10
    },
    {
      "epoch": 0.029895366218236172,
      "grad_norm": 5.738226890563965,
      "learning_rate": 4.9501743896362735e-05,
      "loss": 0.248,
      "step": 20
    },
    {
      "epoch": 0.04484304932735426,
      "grad_norm": 2.689678192138672,
      "learning_rate": 4.92526158445441e-05,
      "loss": 0.2483,
      "step": 30
    },
    {
      "epoch": 0.059790732436472344,
      "grad_norm": 2.20379376411438,
      "learning_rate": 4.900348779272546e-05,
      "loss": 0.2902,
      "step": 40
    },
    {
      "epoch": 0.07473841554559044,
      "grad_norm": 4.501651763916016,
      "learning_rate": 4.875435974090683e-05,
      "loss": 0.178,
      "step": 50
    },
    {
      "epoch": 0.08968609865470852,
      "grad_norm": 3.1523542404174805,
      "learning_rate": 4.850523168908819e-05,
      "loss": 0.1759,
      "step": 60
    },
    {
      "epoch": 0.10463378176382661,
      "grad_norm": 0.6610834002494812,
      "learning_rate": 4.8256103637269556e-05,
      "loss": 0.1521,
      "step": 70
    },
    {
      "epoch": 0.11958146487294469,
      "grad_norm": 2.520716428756714,
      "learning_rate": 4.8006975585450926e-05,
      "loss": 0.1152,
      "step": 80
    },
    {
      "epoch": 0.13452914798206278,
      "grad_norm": 0.08029751479625702,
      "learning_rate": 4.775784753363229e-05,
      "loss": 0.0992,
      "step": 90
    },
    {
      "epoch": 0.14947683109118087,
      "grad_norm": 0.20208504796028137,
      "learning_rate": 4.750871948181366e-05,
      "loss": 0.0772,
      "step": 100
    },
    {
      "epoch": 0.16442451420029897,
      "grad_norm": 0.0417923703789711,
      "learning_rate": 4.725959142999502e-05,
      "loss": 0.1039,
      "step": 110
    },
    {
      "epoch": 0.17937219730941703,
      "grad_norm": 1.029763102531433,
      "learning_rate": 4.7010463378176384e-05,
      "loss": 0.0483,
      "step": 120
    },
    {
      "epoch": 0.19431988041853512,
      "grad_norm": 2.0189974308013916,
      "learning_rate": 4.6761335326357754e-05,
      "loss": 0.0871,
      "step": 130
    },
    {
      "epoch": 0.20926756352765322,
      "grad_norm": 0.1311924010515213,
      "learning_rate": 4.651220727453912e-05,
      "loss": 0.04,
      "step": 140
    },
    {
      "epoch": 0.2242152466367713,
      "grad_norm": 2.244704484939575,
      "learning_rate": 4.626307922272048e-05,
      "loss": 0.2155,
      "step": 150
    },
    {
      "epoch": 0.23916292974588937,
      "grad_norm": 0.9639275670051575,
      "learning_rate": 4.601395117090185e-05,
      "loss": 0.1015,
      "step": 160
    },
    {
      "epoch": 0.25411061285500747,
      "grad_norm": 0.05493377521634102,
      "learning_rate": 4.576482311908321e-05,
      "loss": 0.0152,
      "step": 170
    },
    {
      "epoch": 0.26905829596412556,
      "grad_norm": 0.09249523282051086,
      "learning_rate": 4.5515695067264575e-05,
      "loss": 0.1403,
      "step": 180
    },
    {
      "epoch": 0.28400597907324365,
      "grad_norm": 0.1915442943572998,
      "learning_rate": 4.5266567015445945e-05,
      "loss": 0.1425,
      "step": 190
    },
    {
      "epoch": 0.29895366218236175,
      "grad_norm": 0.12900303304195404,
      "learning_rate": 4.501743896362731e-05,
      "loss": 0.0645,
      "step": 200
    },
    {
      "epoch": 0.31390134529147984,
      "grad_norm": 0.13011932373046875,
      "learning_rate": 4.476831091180867e-05,
      "loss": 0.0699,
      "step": 210
    },
    {
      "epoch": 0.32884902840059793,
      "grad_norm": 0.11536114662885666,
      "learning_rate": 4.451918285999004e-05,
      "loss": 0.0047,
      "step": 220
    },
    {
      "epoch": 0.34379671150971597,
      "grad_norm": 0.04631148651242256,
      "learning_rate": 4.42700548081714e-05,
      "loss": 0.0297,
      "step": 230
    },
    {
      "epoch": 0.35874439461883406,
      "grad_norm": 0.03345618396997452,
      "learning_rate": 4.4020926756352766e-05,
      "loss": 0.0016,
      "step": 240
    },
    {
      "epoch": 0.37369207772795215,
      "grad_norm": 0.024730565026402473,
      "learning_rate": 4.3771798704534136e-05,
      "loss": 0.0793,
      "step": 250
    },
    {
      "epoch": 0.38863976083707025,
      "grad_norm": 0.042831454426050186,
      "learning_rate": 4.35226706527155e-05,
      "loss": 0.0741,
      "step": 260
    },
    {
      "epoch": 0.40358744394618834,
      "grad_norm": 0.2957206666469574,
      "learning_rate": 4.327354260089686e-05,
      "loss": 0.06,
      "step": 270
    },
    {
      "epoch": 0.41853512705530643,
      "grad_norm": 0.07549894601106644,
      "learning_rate": 4.302441454907823e-05,
      "loss": 0.0794,
      "step": 280
    },
    {
      "epoch": 0.4334828101644245,
      "grad_norm": 0.16536852717399597,
      "learning_rate": 4.2775286497259594e-05,
      "loss": 0.0355,
      "step": 290
    },
    {
      "epoch": 0.4484304932735426,
      "grad_norm": 2.6650798320770264,
      "learning_rate": 4.2526158445440964e-05,
      "loss": 0.0655,
      "step": 300
    },
    {
      "epoch": 0.4633781763826607,
      "grad_norm": 1.0209296941757202,
      "learning_rate": 4.227703039362233e-05,
      "loss": 0.0043,
      "step": 310
    },
    {
      "epoch": 0.47832585949177875,
      "grad_norm": 0.9628285765647888,
      "learning_rate": 4.202790234180369e-05,
      "loss": 0.0408,
      "step": 320
    },
    {
      "epoch": 0.49327354260089684,
      "grad_norm": 0.10319355130195618,
      "learning_rate": 4.177877428998506e-05,
      "loss": 0.0384,
      "step": 330
    },
    {
      "epoch": 0.5082212257100149,
      "grad_norm": 0.04501067101955414,
      "learning_rate": 4.152964623816642e-05,
      "loss": 0.0024,
      "step": 340
    },
    {
      "epoch": 0.523168908819133,
      "grad_norm": 0.023317143321037292,
      "learning_rate": 4.1280518186347785e-05,
      "loss": 0.0388,
      "step": 350
    },
    {
      "epoch": 0.5381165919282511,
      "grad_norm": 0.02175750955939293,
      "learning_rate": 4.1031390134529155e-05,
      "loss": 0.025,
      "step": 360
    },
    {
      "epoch": 0.5530642750373692,
      "grad_norm": 0.07082485407590866,
      "learning_rate": 4.078226208271052e-05,
      "loss": 0.1636,
      "step": 370
    },
    {
      "epoch": 0.5680119581464873,
      "grad_norm": 0.09988071769475937,
      "learning_rate": 4.053313403089188e-05,
      "loss": 0.0384,
      "step": 380
    },
    {
      "epoch": 0.5829596412556054,
      "grad_norm": 0.07008460909128189,
      "learning_rate": 4.028400597907325e-05,
      "loss": 0.0374,
      "step": 390
    },
    {
      "epoch": 0.5979073243647235,
      "grad_norm": 0.07219507545232773,
      "learning_rate": 4.003487792725461e-05,
      "loss": 0.0806,
      "step": 400
    },
    {
      "epoch": 0.6128550074738416,
      "grad_norm": 0.0893343985080719,
      "learning_rate": 3.9785749875435976e-05,
      "loss": 0.003,
      "step": 410
    },
    {
      "epoch": 0.6278026905829597,
      "grad_norm": 0.06014014407992363,
      "learning_rate": 3.953662182361734e-05,
      "loss": 0.0025,
      "step": 420
    },
    {
      "epoch": 0.6427503736920778,
      "grad_norm": 10.233987808227539,
      "learning_rate": 3.928749377179871e-05,
      "loss": 0.0775,
      "step": 430
    },
    {
      "epoch": 0.6576980568011959,
      "grad_norm": 0.06870736926794052,
      "learning_rate": 3.903836571998007e-05,
      "loss": 0.0432,
      "step": 440
    },
    {
      "epoch": 0.672645739910314,
      "grad_norm": 0.11284008622169495,
      "learning_rate": 3.8789237668161435e-05,
      "loss": 0.076,
      "step": 450
    },
    {
      "epoch": 0.6875934230194319,
      "grad_norm": 0.11730726063251495,
      "learning_rate": 3.8540109616342804e-05,
      "loss": 0.0045,
      "step": 460
    },
    {
      "epoch": 0.70254110612855,
      "grad_norm": 31.292404174804688,
      "learning_rate": 3.829098156452417e-05,
      "loss": 0.0208,
      "step": 470
    },
    {
      "epoch": 0.7174887892376681,
      "grad_norm": 0.06805533170700073,
      "learning_rate": 3.804185351270553e-05,
      "loss": 0.0898,
      "step": 480
    },
    {
      "epoch": 0.7324364723467862,
      "grad_norm": 0.05653975531458855,
      "learning_rate": 3.77927254608869e-05,
      "loss": 0.0254,
      "step": 490
    },
    {
      "epoch": 0.7473841554559043,
      "grad_norm": 0.04716372489929199,
      "learning_rate": 3.754359740906826e-05,
      "loss": 0.0042,
      "step": 500
    },
    {
      "epoch": 0.7623318385650224,
      "grad_norm": 0.04129564017057419,
      "learning_rate": 3.7294469357249626e-05,
      "loss": 0.0403,
      "step": 510
    },
    {
      "epoch": 0.7772795216741405,
      "grad_norm": 0.31847167015075684,
      "learning_rate": 3.704534130543099e-05,
      "loss": 0.0477,
      "step": 520
    },
    {
      "epoch": 0.7922272047832586,
      "grad_norm": 0.08746617287397385,
      "learning_rate": 3.679621325361236e-05,
      "loss": 0.0022,
      "step": 530
    },
    {
      "epoch": 0.8071748878923767,
      "grad_norm": 0.02513471245765686,
      "learning_rate": 3.654708520179372e-05,
      "loss": 0.0014,
      "step": 540
    },
    {
      "epoch": 0.8221225710014948,
      "grad_norm": 0.05705740675330162,
      "learning_rate": 3.6297957149975084e-05,
      "loss": 0.1198,
      "step": 550
    },
    {
      "epoch": 0.8370702541106129,
      "grad_norm": 0.04277932271361351,
      "learning_rate": 3.6048829098156454e-05,
      "loss": 0.0371,
      "step": 560
    },
    {
      "epoch": 0.852017937219731,
      "grad_norm": 0.13614608347415924,
      "learning_rate": 3.5799701046337816e-05,
      "loss": 0.0383,
      "step": 570
    },
    {
      "epoch": 0.866965620328849,
      "grad_norm": 0.123533234000206,
      "learning_rate": 3.555057299451918e-05,
      "loss": 0.0342,
      "step": 580
    },
    {
      "epoch": 0.8819133034379671,
      "grad_norm": 2.075441837310791,
      "learning_rate": 3.530144494270055e-05,
      "loss": 0.0899,
      "step": 590
    },
    {
      "epoch": 0.8968609865470852,
      "grad_norm": 0.14482444524765015,
      "learning_rate": 3.505231689088191e-05,
      "loss": 0.0389,
      "step": 600
    },
    {
      "epoch": 0.9118086696562033,
      "grad_norm": 0.0588284507393837,
      "learning_rate": 3.4803188839063275e-05,
      "loss": 0.0036,
      "step": 610
    },
    {
      "epoch": 0.9267563527653214,
      "grad_norm": 0.06146470457315445,
      "learning_rate": 3.4554060787244645e-05,
      "loss": 0.0722,
      "step": 620
    },
    {
      "epoch": 0.9417040358744395,
      "grad_norm": 0.10545487701892853,
      "learning_rate": 3.430493273542601e-05,
      "loss": 0.0349,
      "step": 630
    },
    {
      "epoch": 0.9566517189835575,
      "grad_norm": 0.07505655288696289,
      "learning_rate": 3.405580468360738e-05,
      "loss": 0.052,
      "step": 640
    },
    {
      "epoch": 0.9715994020926756,
      "grad_norm": 0.08322012424468994,
      "learning_rate": 3.380667663178874e-05,
      "loss": 0.0028,
      "step": 650
    },
    {
      "epoch": 0.9865470852017937,
      "grad_norm": 0.016908051446080208,
      "learning_rate": 3.35575485799701e-05,
      "loss": 0.0188,
      "step": 660
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.990273118019104,
      "eval_loss": 0.05534307286143303,
      "eval_runtime": 255.9875,
      "eval_samples_per_second": 10.442,
      "eval_steps_per_second": 0.656,
      "step": 669
    },
    {
      "epoch": 1.0014947683109119,
      "grad_norm": 0.024462584406137466,
      "learning_rate": 3.330842052815147e-05,
      "loss": 0.0512,
      "step": 670
    },
    {
      "epoch": 1.0164424514200299,
      "grad_norm": 0.03712042048573494,
      "learning_rate": 3.3059292476332835e-05,
      "loss": 0.0266,
      "step": 680
    },
    {
      "epoch": 1.031390134529148,
      "grad_norm": 0.026331426575779915,
      "learning_rate": 3.28101644245142e-05,
      "loss": 0.001,
      "step": 690
    },
    {
      "epoch": 1.046337817638266,
      "grad_norm": 0.026019154116511345,
      "learning_rate": 3.256103637269557e-05,
      "loss": 0.045,
      "step": 700
    },
    {
      "epoch": 1.0612855007473843,
      "grad_norm": 0.03214028850197792,
      "learning_rate": 3.231190832087693e-05,
      "loss": 0.006,
      "step": 710
    },
    {
      "epoch": 1.0762331838565022,
      "grad_norm": 0.04908352717757225,
      "learning_rate": 3.2062780269058294e-05,
      "loss": 0.0011,
      "step": 720
    },
    {
      "epoch": 1.0911808669656202,
      "grad_norm": 0.027921078726649284,
      "learning_rate": 3.1813652217239664e-05,
      "loss": 0.0008,
      "step": 730
    },
    {
      "epoch": 1.1061285500747384,
      "grad_norm": 0.016798803582787514,
      "learning_rate": 3.1564524165421026e-05,
      "loss": 0.0029,
      "step": 740
    },
    {
      "epoch": 1.1210762331838564,
      "grad_norm": 0.01249523926526308,
      "learning_rate": 3.131539611360239e-05,
      "loss": 0.0419,
      "step": 750
    },
    {
      "epoch": 1.1360239162929746,
      "grad_norm": 0.019519364461302757,
      "learning_rate": 3.106626806178376e-05,
      "loss": 0.045,
      "step": 760
    },
    {
      "epoch": 1.1509715994020926,
      "grad_norm": 0.018605362623929977,
      "learning_rate": 3.081714000996512e-05,
      "loss": 0.0007,
      "step": 770
    },
    {
      "epoch": 1.1659192825112108,
      "grad_norm": 0.018238060176372528,
      "learning_rate": 3.0568011958146485e-05,
      "loss": 0.0009,
      "step": 780
    },
    {
      "epoch": 1.1808669656203288,
      "grad_norm": 0.014064514078199863,
      "learning_rate": 3.0318883906327854e-05,
      "loss": 0.0006,
      "step": 790
    },
    {
      "epoch": 1.195814648729447,
      "grad_norm": 0.011442483402788639,
      "learning_rate": 3.0069755854509217e-05,
      "loss": 0.0005,
      "step": 800
    },
    {
      "epoch": 1.210762331838565,
      "grad_norm": 0.030458157882094383,
      "learning_rate": 2.982062780269058e-05,
      "loss": 0.0004,
      "step": 810
    },
    {
      "epoch": 1.2257100149476832,
      "grad_norm": 28.48387336730957,
      "learning_rate": 2.957149975087195e-05,
      "loss": 0.0598,
      "step": 820
    },
    {
      "epoch": 1.2406576980568012,
      "grad_norm": 0.025724703446030617,
      "learning_rate": 2.9322371699053313e-05,
      "loss": 0.0006,
      "step": 830
    },
    {
      "epoch": 1.2556053811659194,
      "grad_norm": 0.46591100096702576,
      "learning_rate": 2.9073243647234683e-05,
      "loss": 0.1826,
      "step": 840
    },
    {
      "epoch": 1.2705530642750373,
      "grad_norm": 0.04093802720308304,
      "learning_rate": 2.8824115595416045e-05,
      "loss": 0.0282,
      "step": 850
    },
    {
      "epoch": 1.2855007473841553,
      "grad_norm": 0.016478493809700012,
      "learning_rate": 2.857498754359741e-05,
      "loss": 0.0194,
      "step": 860
    },
    {
      "epoch": 1.3004484304932735,
      "grad_norm": 0.02856367640197277,
      "learning_rate": 2.8325859491778778e-05,
      "loss": 0.0824,
      "step": 870
    },
    {
      "epoch": 1.3153961136023917,
      "grad_norm": 2.1273956298828125,
      "learning_rate": 2.807673143996014e-05,
      "loss": 0.0451,
      "step": 880
    },
    {
      "epoch": 1.3303437967115097,
      "grad_norm": 17.59483528137207,
      "learning_rate": 2.7827603388141504e-05,
      "loss": 0.0125,
      "step": 890
    },
    {
      "epoch": 1.3452914798206277,
      "grad_norm": 0.04902857542037964,
      "learning_rate": 2.7578475336322873e-05,
      "loss": 0.0348,
      "step": 900
    },
    {
      "epoch": 1.360239162929746,
      "grad_norm": 0.05590145289897919,
      "learning_rate": 2.7329347284504236e-05,
      "loss": 0.002,
      "step": 910
    },
    {
      "epoch": 1.375186846038864,
      "grad_norm": 0.05430768057703972,
      "learning_rate": 2.70802192326856e-05,
      "loss": 0.0317,
      "step": 920
    },
    {
      "epoch": 1.390134529147982,
      "grad_norm": 0.05170144885778427,
      "learning_rate": 2.683109118086697e-05,
      "loss": 0.0356,
      "step": 930
    },
    {
      "epoch": 1.4050822122571,
      "grad_norm": 0.04783609136939049,
      "learning_rate": 2.6581963129048332e-05,
      "loss": 0.0009,
      "step": 940
    },
    {
      "epoch": 1.4200298953662183,
      "grad_norm": 0.013665801845490932,
      "learning_rate": 2.6332835077229695e-05,
      "loss": 0.0007,
      "step": 950
    },
    {
      "epoch": 1.4349775784753362,
      "grad_norm": 0.012912550941109657,
      "learning_rate": 2.6083707025411064e-05,
      "loss": 0.0272,
      "step": 960
    },
    {
      "epoch": 1.4499252615844545,
      "grad_norm": 0.018005486577749252,
      "learning_rate": 2.5834578973592427e-05,
      "loss": 0.0004,
      "step": 970
    },
    {
      "epoch": 1.4648729446935724,
      "grad_norm": 1.9217735528945923,
      "learning_rate": 2.558545092177379e-05,
      "loss": 0.0517,
      "step": 980
    },
    {
      "epoch": 1.4798206278026906,
      "grad_norm": 0.021687272936105728,
      "learning_rate": 2.533632286995516e-05,
      "loss": 0.047,
      "step": 990
    },
    {
      "epoch": 1.4947683109118086,
      "grad_norm": 0.01874368265271187,
      "learning_rate": 2.5087194818136523e-05,
      "loss": 0.0241,
      "step": 1000
    },
    {
      "epoch": 1.5097159940209268,
      "grad_norm": 0.017986692488193512,
      "learning_rate": 2.483806676631789e-05,
      "loss": 0.0006,
      "step": 1010
    },
    {
      "epoch": 1.5246636771300448,
      "grad_norm": 0.015351161360740662,
      "learning_rate": 2.4588938714499255e-05,
      "loss": 0.0858,
      "step": 1020
    },
    {
      "epoch": 1.5396113602391628,
      "grad_norm": 0.021504463627934456,
      "learning_rate": 2.4339810662680618e-05,
      "loss": 0.0015,
      "step": 1030
    },
    {
      "epoch": 1.554559043348281,
      "grad_norm": 0.037455957382917404,
      "learning_rate": 2.4090682610861985e-05,
      "loss": 0.0357,
      "step": 1040
    },
    {
      "epoch": 1.5695067264573992,
      "grad_norm": 0.014508933760225773,
      "learning_rate": 2.384155455904335e-05,
      "loss": 0.0006,
      "step": 1050
    },
    {
      "epoch": 1.5844544095665172,
      "grad_norm": 0.011483769863843918,
      "learning_rate": 2.3592426507224717e-05,
      "loss": 0.0005,
      "step": 1060
    },
    {
      "epoch": 1.5994020926756352,
      "grad_norm": 0.010483377613127232,
      "learning_rate": 2.334329845540608e-05,
      "loss": 0.0046,
      "step": 1070
    },
    {
      "epoch": 1.6143497757847534,
      "grad_norm": 0.0105826947838068,
      "learning_rate": 2.3094170403587446e-05,
      "loss": 0.0033,
      "step": 1080
    },
    {
      "epoch": 1.6292974588938716,
      "grad_norm": 0.025116367265582085,
      "learning_rate": 2.2845042351768813e-05,
      "loss": 0.0005,
      "step": 1090
    },
    {
      "epoch": 1.6442451420029895,
      "grad_norm": 0.05037365108728409,
      "learning_rate": 2.2595914299950176e-05,
      "loss": 0.0965,
      "step": 1100
    },
    {
      "epoch": 1.6591928251121075,
      "grad_norm": 0.07013501971960068,
      "learning_rate": 2.2346786248131542e-05,
      "loss": 0.0016,
      "step": 1110
    },
    {
      "epoch": 1.6741405082212257,
      "grad_norm": 0.06344209611415863,
      "learning_rate": 2.2097658196312908e-05,
      "loss": 0.0313,
      "step": 1120
    },
    {
      "epoch": 1.689088191330344,
      "grad_norm": 0.04099051281809807,
      "learning_rate": 2.184853014449427e-05,
      "loss": 0.0631,
      "step": 1130
    },
    {
      "epoch": 1.704035874439462,
      "grad_norm": 0.06304658949375153,
      "learning_rate": 2.1599402092675637e-05,
      "loss": 0.0069,
      "step": 1140
    },
    {
      "epoch": 1.71898355754858,
      "grad_norm": 0.02205747365951538,
      "learning_rate": 2.1350274040857e-05,
      "loss": 0.023,
      "step": 1150
    },
    {
      "epoch": 1.733931240657698,
      "grad_norm": 0.0229546669870615,
      "learning_rate": 2.1101145989038367e-05,
      "loss": 0.0016,
      "step": 1160
    },
    {
      "epoch": 1.7488789237668163,
      "grad_norm": 0.019271720200777054,
      "learning_rate": 2.085201793721973e-05,
      "loss": 0.0639,
      "step": 1170
    },
    {
      "epoch": 1.7638266068759343,
      "grad_norm": 0.02214772067964077,
      "learning_rate": 2.0602889885401096e-05,
      "loss": 0.0238,
      "step": 1180
    },
    {
      "epoch": 1.7787742899850523,
      "grad_norm": 0.021977491676807404,
      "learning_rate": 2.0353761833582462e-05,
      "loss": 0.0011,
      "step": 1190
    },
    {
      "epoch": 1.7937219730941703,
      "grad_norm": 0.015639932826161385,
      "learning_rate": 2.0104633781763825e-05,
      "loss": 0.0006,
      "step": 1200
    },
    {
      "epoch": 1.8086696562032885,
      "grad_norm": 0.01192895881831646,
      "learning_rate": 1.985550572994519e-05,
      "loss": 0.0005,
      "step": 1210
    },
    {
      "epoch": 1.8236173393124067,
      "grad_norm": 0.013445050455629826,
      "learning_rate": 1.9606377678126557e-05,
      "loss": 0.0005,
      "step": 1220
    },
    {
      "epoch": 1.8385650224215246,
      "grad_norm": 0.16093729436397552,
      "learning_rate": 1.9357249626307924e-05,
      "loss": 0.0772,
      "step": 1230
    },
    {
      "epoch": 1.8535127055306426,
      "grad_norm": 0.039354946464300156,
      "learning_rate": 1.9108121574489287e-05,
      "loss": 0.0475,
      "step": 1240
    },
    {
      "epoch": 1.8684603886397608,
      "grad_norm": 0.05221769958734512,
      "learning_rate": 1.8858993522670653e-05,
      "loss": 0.043,
      "step": 1250
    },
    {
      "epoch": 1.883408071748879,
      "grad_norm": 2.4175686836242676,
      "learning_rate": 1.860986547085202e-05,
      "loss": 0.0444,
      "step": 1260
    },
    {
      "epoch": 1.898355754857997,
      "grad_norm": 0.05405934900045395,
      "learning_rate": 1.8360737419033382e-05,
      "loss": 0.0016,
      "step": 1270
    },
    {
      "epoch": 1.913303437967115,
      "grad_norm": 0.04439832270145416,
      "learning_rate": 1.811160936721475e-05,
      "loss": 0.0016,
      "step": 1280
    },
    {
      "epoch": 1.9282511210762332,
      "grad_norm": 0.03729691356420517,
      "learning_rate": 1.7862481315396115e-05,
      "loss": 0.0436,
      "step": 1290
    },
    {
      "epoch": 1.9431988041853514,
      "grad_norm": 0.024750126525759697,
      "learning_rate": 1.7613353263577478e-05,
      "loss": 0.0037,
      "step": 1300
    },
    {
      "epoch": 1.9581464872944694,
      "grad_norm": 0.024513253942131996,
      "learning_rate": 1.7364225211758844e-05,
      "loss": 0.0009,
      "step": 1310
    },
    {
      "epoch": 1.9730941704035874,
      "grad_norm": 0.018364135175943375,
      "learning_rate": 1.711509715994021e-05,
      "loss": 0.0487,
      "step": 1320
    },
    {
      "epoch": 1.9880418535127056,
      "grad_norm": 0.034196190536022186,
      "learning_rate": 1.6865969108121576e-05,
      "loss": 0.0011,
      "step": 1330
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.993640124797821,
      "eval_loss": 0.03686162084341049,
      "eval_runtime": 256.2604,
      "eval_samples_per_second": 10.431,
      "eval_steps_per_second": 0.656,
      "step": 1338
    }
  ],
  "logging_steps": 10,
  "max_steps": 2007,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1406197035371520.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
